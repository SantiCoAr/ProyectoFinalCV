{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sesi√≥n 2:** Calibraci√≥n de C√°mara üì∑‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(\"OpenCV should be 4.8.0.76 Current version:\", cv2.__version__)\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado A: Calibraci√≥n de c√°mara** (derecha e izquierda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se realiza la calibraci√≥n de dos c√°maras de un sistema estereosc√≥pico. Para ello se trabajar√° con las im√°genes de las carpetas ``left`` y ``right``. En primer lugar se trabajar√° con la carpeta ``left``. Posteriormente, deber√° repetir el proceso con las im√°genes en la carpeta ``right``. Ambas carpetas contienen im√°genes con las que se calibrar√°n las c√°maras. En ellas aparece el patr√≥n de calibraci√≥n en diferentes posiciones y orientaciones. Estas im√°genes ser√°n los datos de entrada.\n",
    "\n",
    "Los pasos que deber√° seguir para calibrar una c√°mara son:\n",
    "\n",
    "1. Defina y ejecute el m√©todo para cargar im√°genes ``load_images()``.\n",
    "2. Detecte las esquinas de los patrones usando ``cv2.findChessboardCorners()``. Refine las detecciones con ``cv2.cornerSubPix()``.\n",
    "3. Compruebe que las detecciones son correctas dibujando los resultados con ``cv2.drawChessboardCorners()``.\n",
    "4. Defina y ejecute el m√©todo ``get_chessboard_points(chessboard_shape, dx, dy)`` que proporcione las coordenadas 3D de las esquinas del patr√≥n. El sistema de referencia utilizado deber√° estar anclado al propio patr√≥n.\n",
    "5. Utilice ``cv2.calibrateCamera`` para obtener los par√°metros de calibraci√≥n para la c√°mara izquierda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.1:** Defina y ejecute el m√©todo para cargar im√°genes ``load_images()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filenames: List) -> List:\n",
    "    return [cv2.imread(filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Build a list containing the paths of all images from the left camera\n",
    "imgs_path = [\"../data/\" + item for item in os.listdir(\"../data/\") if item.endswith(\".jpg\")]\n",
    "imgs = load_images(imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.2:** Detecte las esquinas de los patrones usando ``cv2.findChessboardCorners()``. Refine las detecciones con ``cv2.cornerSubPix()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Find corners with cv2.findChessboardCorners()\n",
    "chessboard_shape = (7, 9)\n",
    "corners = []\n",
    "for img in imgs:\n",
    "    ret, corner = cv2.findChessboardCorners(img, chessboard_shape)\n",
    "    corners.append((ret, corner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_copy = copy.deepcopy(corners)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.01)\n",
    "\n",
    "# TODO To refine corner detections with cv2.cornerSubPix() you need to input grayscale images. Build a list containing grayscale images.\n",
    "imgs_gray = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in imgs]\n",
    "\n",
    "corners_refined = [cv2.cornerSubPix(i, cor[1], (7, 9), (-1, -1), criteria) if cor[0] else [] for i, cor in zip(imgs_gray, corners_copy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.3:** Compruebe que las detecciones son correctas dibujando los resultados con ``cv2.drawChessboardCorners()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_copy = copy.deepcopy(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Use cv2.drawChessboardCorners() to draw the cornes\n",
    "list_with_corners = []\n",
    "for i in range(len(corners)):\n",
    "    list_with_corners.append(cv2.drawChessboardCorners(imgs_copy[i], patternSize=chessboard_shape, patternWasFound=corners[i][0], corners=corners[i][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, window_name=\"Image\"):\n",
    "    cv2.imshow(window_name, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def write_image(img, filename):\n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "for image in list_with_corners:\n",
    "    show_image(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.4:** Defina y ejecute el m√©todo ``get_chessboard_points(chessboard_shape, dx, dy)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Design the method. It should return a np.array with np.float32 elements\n",
    "def get_chessboard_points(chessboard_shape, dx, dy):\n",
    "    rows, cols = chessboard_shape\n",
    "    objp = np.zeros((rows * cols, 3), np.float32)\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            objp[y * cols + x, 0] = x * dx\n",
    "            objp[y * cols + x, 1] = y * dy\n",
    "            objp[y * cols + x, 2] = 0\n",
    "    return objp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO You need the points for every image, not just one (consider a list comprehension)\n",
    "chessboard_points = get_chessboard_points((6, 8), 30, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea A.5:** Utilice ``cv2.calibrateCamera()`` para obtener los par√°metros de calibraci√≥n para la c√°mara izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data and get only those with adequate detections\n",
    "valid_corners = [cor[1] for cor in corners if cor[0]]\n",
    "# Convert list to numpy array\n",
    "valid_corners = np.asarray(valid_corners, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "obj= np.array([chessboard_points]*18)\n",
    "rms, intrinsics, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(objectPoints=obj, imagePoints=valid_corners, imageSize=imgs[0].shape[:2], cameraMatrix=np.zeros((3,3)), distCoeffs=np.zeros((1,4)))\n",
    "\n",
    "\n",
    "# Obtain extrinsics\n",
    "extrinsics = list(map(lambda rvec, tvec: np.hstack((cv2.Rodrigues(rvec)[0], tvec)), rvecs, tvecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print outputs\n",
    "print(\"Intrinsics:\\n\", intrinsics)\n",
    "print(\"Distortion coefficients:\\n\", dist_coeffs)\n",
    "print(\"Root mean squared reprojection error:\\n\", rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.1:** Repita el proceso (carga de im√°genes, detecci√≥n y comprobaci√≥n de esquinas, etc.) para la c√°mara derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Build a list containing the paths of all images from the left camera\n",
    "imgs_path = [\"../data/right/\" + item for item in os.listdir(\"../data/right/\") if item.endswith(\".jpg\")]\n",
    "imgs = load_images(imgs_path) \n",
    "\n",
    "# TODO Find corners with cv2.findChessboardCorners()\n",
    "chessboard_shape = (8, 6)\n",
    "corners = []\n",
    "for img in imgs:\n",
    "    ret, corner = cv2.findChessboardCorners(img, chessboard_shape)\n",
    "    corners.append((ret, corner))\n",
    "\n",
    "corners_copy = copy.deepcopy(corners)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.01)\n",
    "\n",
    "# TODO To refine corner detections with cv2.cornerSubPix() you need to input grayscale images. Build a list containing grayscale images.\n",
    "imgs_gray = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in imgs]\n",
    "\n",
    "corners_refined = [cv2.cornerSubPix(i, cor[1], (8, 6), (-1, -1), criteria) if cor[0] else [] for i, cor in zip(imgs_gray, corners_copy)]\n",
    "\n",
    "imgs_copy = copy.deepcopy(imgs)\n",
    "\n",
    "# TODO Use cv2.drawChessboardCorners() to draw the cornes\n",
    "list_with_corners = []\n",
    "for i in range(len(corners)):\n",
    "    list_with_corners.append(cv2.drawChessboardCorners(imgs_copy[i], patternSize=chessboard_shape, patternWasFound=corners[i][0], corners=corners[i][1]))\n",
    "\n",
    "for image in list_with_corners[:2]:\n",
    "    show_image(image)\n",
    "\n",
    "# TODO You need the points for every image, not just one (consider a list comprehension)\n",
    "chessboard_points = get_chessboard_points((6, 8), 30, 30)\n",
    "\n",
    "# Filter data and get only those with adequate detections\n",
    "valid_corners = [cor[1] for cor in corners if cor[0]]\n",
    "# Convert list to numpy array\n",
    "valid_corners = np.asarray(valid_corners, dtype=np.float32)\n",
    "\n",
    "# TODO\n",
    "obj= np.array([chessboard_points]*18)\n",
    "rms, intrinsics, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(objectPoints=obj, imagePoints=valid_corners, imageSize=imgs[0].shape[:2], cameraMatrix=np.zeros((3,3)), distCoeffs=np.zeros((1,4)))\n",
    "\n",
    "# Obtain extrinsics\n",
    "extrinsics = list(map(lambda rvec, tvec: np.hstack((cv2.Rodrigues(rvec)[0], tvec)), rvecs, tvecs))\n",
    "\n",
    "# Print outputs\n",
    "print(\"Intrinsics:\\n\", intrinsics)\n",
    "print(\"Extrinsics:\\n\", extrinsics[0])\n",
    "print(\"Distortion coefficients:\\n\", dist_coeffs)\n",
    "print(\"Root mean squared reprojection error:\\n\", rms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.2:** Diferencias entre cv2.findChessboardCorners() y cv2.cornerSubPix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = []\n",
    "for i in range(2):\n",
    "    if corners[i][0] and len(corners_refined[i]) > 0:\n",
    "        # Copias para dibujar\n",
    "        vis_coarse  = imgs[i].copy()\n",
    "        vis_refined = imgs[i].copy()\n",
    "\n",
    "        # Dibujo original\n",
    "        cv2.drawChessboardCorners(\n",
    "            vis_coarse, chessboard_shape, corners[i][1], True\n",
    "        )\n",
    "\n",
    "        # Dibujo refinado\n",
    "        cv2.drawChessboardCorners(\n",
    "            vis_refined, chessboard_shape, corners_refined[i], True\n",
    "        )\n",
    "\n",
    "        # Mostrar las im√°genes\n",
    "        show_image(vis_coarse)\n",
    "        show_image(vis_refined)\n",
    "\n",
    "        # M√©tricas: desplazamiento medio y m√°ximo (en p√≠xeles)\n",
    "        c0 = corners[i][1].reshape(-1, 2).astype(np.float32)\n",
    "        c1 = corners_refined[i].reshape(-1, 2).astype(np.float32)\n",
    "        d  = np.linalg.norm(c0 - c1, axis=1)\n",
    "        out.append((i, float(d.mean()), float(d.max())))\n",
    "\n",
    "# M√©tricas para cada imagen\n",
    "for i, mean_shift, max_shift in out:\n",
    "    print(f\"[A.2] Img {i}: mean shift = {mean_shift:.3f} px | max shift = {max_shift:.3f} px\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta A.3:** N√∫mero m√≠nimo de im√°genes necesarias para calibrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# N total de im√°genes v√°lidas detectadas\n",
    "n_total = len(valid_corners)\n",
    "print(f\"Total de im√°genes v√°lidas disponibles: {n_total}\")\n",
    "\n",
    "# Lista de tama√±os de subconjunto (n√∫mero de im√°genes a usar)\n",
    "subset_sizes = [3, 5, 7, 9, 11, 13, 15, n_total]\n",
    "\n",
    "# Listas para guardar resultados\n",
    "rms_values = []\n",
    "\n",
    "# Calibrar con distintos tama√±os de conjunto\n",
    "for n in subset_sizes:\n",
    "    # Seleccionar las primeras n im√°genes v√°lidas\n",
    "    obj_subset = [chessboard_points] * n\n",
    "    img_subset = valid_corners[:n]\n",
    "\n",
    "    rms, K, D, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objectPoints=obj_subset,\n",
    "        imagePoints=img_subset,\n",
    "        imageSize=imgs[0].shape[:2],\n",
    "        cameraMatrix=np.zeros((3,3)),\n",
    "        distCoeffs=np.zeros((1,4))\n",
    "    )\n",
    "\n",
    "    rms_values.append(rms)\n",
    "    print(f\"Usando {n} im√°genes ‚Üí RMS = {rms:.4f}\")\n",
    "\n",
    "# Grafico de Pareto\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(subset_sizes, rms_values, marker='o')\n",
    "plt.title(\"Diagrama de Pareto: n√∫mero de im√°genes vs RMS\")\n",
    "plt.xlabel(\"N√∫mero de im√°genes utilizadas\")\n",
    "plt.ylabel(\"Error RMS (px)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apartado B: Correcci√≥n de distorsi√≥n** (ojo de pez)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se trabajar√° en la correcci√≥n de la distorsi√≥n debido a lentes de ojo de pez. Primero se calibrar√° una c√°mara con este tipo de lente, utilizando las im√°genes de la carpeta ``fisheye``. Posteriormente se utilizar√°n estos par√°metros de calibraci√≥n para corregir la distorsi√≥n de una de las im√°genes de calibraci√≥n.\n",
    "\n",
    "Los pasos que deber√° seguir para calibrar una c√°mara con distorsi√≥n de ojo de pez son:\n",
    "\n",
    "1. Reutilice el m√©todo ``load_images()`` para cargar las im√°genes de la carpeta ``fisheye``.\n",
    "2. Detecte las equinas procesando las im√°genes con los m√©todos ``cv2.findChessboardCorners()`` y ``cv2.cornerSubPix()``.\n",
    "3. Reutilice la funci√≥n ``get_chessboard_points()`` para obtener las coordenadas del tablero.\n",
    "4. Defina los argumentos para la funci√≥n de calibraci√≥n.\n",
    "5. Calibre con ``cv2.fisheye.calibrate()``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.1:** Reutilice el m√©todo ``load_images()`` para cargar las im√°genes de la carpeta ``fisheye``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Build a list containing the paths of all images from the fisheye camera and load images\n",
    "fisheye_imgs_path = [\"../data/fisheye/\" + item for item in os.listdir(\"../data/fisheye/\") if item.endswith(\".jpg\")]\n",
    "fisheye_imgs = load_images(fisheye_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.2:** Detecte las equinas procesando las im√°genes con los m√©todos ``cv2.findChessboardCorners()`` y ``cv2.cornerSubPix()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_corners = []\n",
    "# Parameters for cv2.cornerSubPix()\n",
    "subpix_criteria = (cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1)\n",
    "chessboard_shape = (7, 6)\n",
    "\n",
    "#TODO Complete the required parts of the loop\n",
    "for img in fisheye_imgs:\n",
    "    # TODO parse arguments to cv2.findChessboardCorners()\n",
    "    ret, corners = cv2.findChessboardCorners(image=img, patternSize=chessboard_shape)\n",
    "    \n",
    "    # TODO convert image to grayscale to use cv2.cornerSubPix()\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) \n",
    "    if ret:  # Solo si encontr√≥ todas las esquinas\n",
    "        # Refinar posiciones a nivel subp√≠xel\n",
    "        refined_corners = cv2.cornerSubPix(\n",
    "            gray_img,\n",
    "            corners,\n",
    "            (3, 3),\n",
    "            (-1, -1),\n",
    "            subpix_criteria\n",
    "        )\n",
    "        imgs_corners.append(refined_corners)\n",
    "    else:\n",
    "        print(\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.3:** Reutilice la funci√≥n ``get_chessboard_points()`` para obtener las coordenadas del tablero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Define the chessboard dimensions and the lenght of the squares (in [mm])\n",
    "chessboard_dims = (6, 7)\n",
    "length = 0.03\n",
    "# TODO You need the points for every image, not just one (consider a list comprehension)\n",
    "fisheye_chessboard_points = [\n",
    "    get_chessboard_points(chessboard_dims, length, length).astype(np.float64)[np.newaxis, :, :]\n",
    "    for _ in imgs_corners\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.4:** Defina los argumentos para la calibraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for cv2.fisheye.calibrate()\n",
    "calibration_flags = cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC+cv2.fisheye.CALIB_FIX_SKEW\n",
    "intrinsics = np.zeros((3, 3))\n",
    "distortion = np.zeros((4, 1))\n",
    "rotations = [np.zeros((1, 1, 3), dtype=np.float64) for _ in imgs_corners]\n",
    "traslations = [np.zeros((1, 1, 3), dtype=np.float64) for _ in imgs_corners]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tarea B.5:** Calibraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms, _, _, _, _ = \\\n",
    "cv2.fisheye.calibrate(fisheye_chessboard_points, imgs_corners, gray_img.shape[::-1], intrinsics, distortion, rotations, traslations, calibration_flags, subpix_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show intrinsic matrix and distortion coefficients values\n",
    "print(\"Intrinsics:\", intrinsics)\n",
    "print(\"Distortion:\", distortion)\n",
    "print(\"RMSE:\", rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pregunta B.1:** Corrija la distorsi√≥n de las 2 primeras im√°genes de la carpeta ``fisheye``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Search in the documentation to define 'dim'\n",
    "dim = (fisheye_imgs[0].shape[1], fisheye_imgs[0].shape[0])\n",
    "map1, map2 = cv2.fisheye.initUndistortRectifyMap(intrinsics, distortion, np.eye(3), intrinsics, dim, cv2.CV_16SC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Homework: correct distortion using cv2.remap()\n",
    "print(\"Intrinsics (K):\\n\", intrinsics)\n",
    "print(\"\\nDistortion (D):\\n\", distortion)\n",
    "\n",
    "# Funci√≥n para undistort usando los mapas encontrados antes\n",
    "def undistort_fisheye_image(img, map1, map2):\n",
    "    # Usamos INTER_LINEAR, podr√≠amos ussar INTER_CUBIC\n",
    "    # BORDER_CONSTANT evita ‚Äúarrastres‚Äù negros por fuera del campo √∫til\n",
    "    return cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "# Generar y guardar las 2 primeras im√°genes sin distorsi√≥n\n",
    "def save_rgb_as_bgr(path, img_rgb):\n",
    "    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(path, img_bgr)\n",
    "\n",
    "undist_0 = undistort_fisheye_image(fisheye_imgs[0], map1, map2)\n",
    "undist_1 = undistort_fisheye_image(fisheye_imgs[1], map1, map2)\n",
    "\n",
    "# Guardamos a disco las fotos\n",
    "save_rgb_as_bgr(\"fisheye_undist_0_C.png\", undist_0)\n",
    "save_rgb_as_bgr(\"fisheye_undist_1_C.png\", undist_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voi-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
